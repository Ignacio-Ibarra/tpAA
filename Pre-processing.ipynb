{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import requests\n",
    "import random\n",
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183810, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nocols = ['Unnamed: 0', 'Unnamed: 0.1']\n",
    "\n",
    "raw_df = pd.read_csv(\"./data/cabaventa.csv\").drop(columns = nocols)\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen funciones accesorias para el recupero de las características del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TipoDato</th>\n",
       "      <th>PorcentajeNulos</th>\n",
       "      <th>ValoresUnicos</th>\n",
       "      <th>Ejemplos</th>\n",
       "      <th>Rangos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>183810</td>\n",
       "      <td>m8Qw6REGK74j9zZd+GRkVw==, 5Uq8...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_type</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_date</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>362</td>\n",
       "      <td>2020-10-02, 2020-12-03, 2020-0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_date</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>449</td>\n",
       "      <td>9999-12-31, 2021-06-05, 2021-0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_on</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>362</td>\n",
       "      <td>2020-10-02, 2020-12-03, 2020-0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>float64</td>\n",
       "      <td>6.23%</td>\n",
       "      <td>69507</td>\n",
       "      <td>-34.612753999999995, -34.55894...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <td>float64</td>\n",
       "      <td>6.23%</td>\n",
       "      <td>70182</td>\n",
       "      <td>-58.41326479999999, -58.475767...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l3</th>\n",
       "      <td>object</td>\n",
       "      <td>1.00%</td>\n",
       "      <td>57</td>\n",
       "      <td>Palermo, Belgrano, Caballito.....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l4</th>\n",
       "      <td>object</td>\n",
       "      <td>96.05%</td>\n",
       "      <td>4</td>\n",
       "      <td>Palermo Hollywood, Palermo Chi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l5</th>\n",
       "      <td>float64</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l6</th>\n",
       "      <td>float64</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>float64</td>\n",
       "      <td>15.30%</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0, 3.0, 1.0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>float64</td>\n",
       "      <td>27.19%</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0, 2.0, 3.0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>float64</td>\n",
       "      <td>13.56%</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0, 2.0, 3.0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_total</th>\n",
       "      <td>float64</td>\n",
       "      <td>33.13%</td>\n",
       "      <td>1601</td>\n",
       "      <td>40.0, 50.0, 45.0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_covered</th>\n",
       "      <td>float64</td>\n",
       "      <td>34.02%</td>\n",
       "      <td>1315</td>\n",
       "      <td>40.0, 35.0, 42.0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>float64</td>\n",
       "      <td>1.85%</td>\n",
       "      <td>9087</td>\n",
       "      <td>110000.0, 120000.0, 115000.0.....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>object</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>USD,ARS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_period</th>\n",
       "      <td>object</td>\n",
       "      <td>51.73%</td>\n",
       "      <td>1</td>\n",
       "      <td>Mensual</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>98827</td>\n",
       "      <td>Departamento - Palermo, Depart...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>141615</td>\n",
       "      <td>Pozo en Villa Crespo. Monoambi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>10</td>\n",
       "      <td>Departamento, PH, Casa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation_type</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>Venta</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TipoDato PorcentajeNulos  ValoresUnicos  \\\n",
       "id                object           0.00%         183810   \n",
       "ad_type           object           0.00%              1   \n",
       "start_date        object           0.00%            362   \n",
       "end_date          object           0.00%            449   \n",
       "created_on        object           0.00%            362   \n",
       "lat              float64           6.23%          69507   \n",
       "lon              float64           6.23%          70182   \n",
       "l1                object           0.00%              1   \n",
       "l2                object           0.00%              1   \n",
       "l3                object           1.00%             57   \n",
       "l4                object          96.05%              4   \n",
       "l5               float64         100.00%              0   \n",
       "l6               float64         100.00%              0   \n",
       "rooms            float64          15.30%             31   \n",
       "bedrooms         float64          27.19%             60   \n",
       "bathrooms        float64          13.56%             19   \n",
       "surface_total    float64          33.13%           1601   \n",
       "surface_covered  float64          34.02%           1315   \n",
       "price            float64           1.85%           9087   \n",
       "currency          object           2.00%              2   \n",
       "price_period      object          51.73%              1   \n",
       "title             object           0.00%          98827   \n",
       "description       object           0.00%         141615   \n",
       "property_type     object           0.00%             10   \n",
       "operation_type    object           0.00%              1   \n",
       "\n",
       "                                          Ejemplos Rangos  \n",
       "id               m8Qw6REGK74j9zZd+GRkVw==, 5Uq8...         \n",
       "ad_type                                  Propiedad         \n",
       "start_date       2020-10-02, 2020-12-03, 2020-0...         \n",
       "end_date         9999-12-31, 2021-06-05, 2021-0...         \n",
       "created_on       2020-10-02, 2020-12-03, 2020-0...         \n",
       "lat              -34.612753999999995, -34.55894...         \n",
       "lon              -58.41326479999999, -58.475767...         \n",
       "l1                                       Argentina         \n",
       "l2                                 Capital Federal         \n",
       "l3               Palermo, Belgrano, Caballito.....         \n",
       "l4               Palermo Hollywood, Palermo Chi...         \n",
       "l5                                                         \n",
       "l6                                                         \n",
       "rooms                             2.0, 3.0, 1.0...         \n",
       "bedrooms                          1.0, 2.0, 3.0...         \n",
       "bathrooms                         1.0, 2.0, 3.0...         \n",
       "surface_total                  40.0, 50.0, 45.0...         \n",
       "surface_covered                40.0, 35.0, 42.0...         \n",
       "price            110000.0, 120000.0, 115000.0.....         \n",
       "currency                                   USD,ARS         \n",
       "price_period                               Mensual         \n",
       "title            Departamento - Palermo, Depart...         \n",
       "description      Pozo en Villa Crespo. Monoambi...         \n",
       "property_type            Departamento, PH, Casa...         \n",
       "operation_type                               Venta         "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rango(col): \n",
    "    col = col.dropna()\n",
    "    if len(col)==0:\n",
    "        return \"\"\n",
    "    if np.issubdtype(col.dtype, np.number):\n",
    "        return \"[\"+\"{:.2f}\".format(col.min())+\",\"+\"{:.2f}\".format(col.max())+\"]\"\n",
    "    else: \n",
    "        return \"\"\n",
    "\n",
    "def ejemplo(col, col_width=30):\n",
    "    uniques = col.dropna().unique()\n",
    "    if len(uniques) == 0: \n",
    "        return \"\"\n",
    "    if len(uniques)<4: \n",
    "        s = \",\".join([str(x) for x in uniques])\n",
    "        if len(s)>col_width:\n",
    "            return s[:col_width]+\"...\"\n",
    "        else:\n",
    "            return s\n",
    "    else:\n",
    "        vcounts = col.value_counts().index\n",
    "        s = \", \".join([str(x) for x in vcounts[:3]])+\"...\"\n",
    "        if len(s)>col_width:\n",
    "            return s[:col_width]+\"...\"\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "\n",
    "def get_dataframe_info(df):\n",
    "    \n",
    "    dtypes = df.dtypes    \n",
    "    nulls = (df.isna().sum()/len(df)).apply(lambda x: \"{:.2%}\".format(x))\n",
    "    nuniques = df.nunique()\n",
    "    ejemplos = df.apply(lambda col: ejemplo(col), axis=0)\n",
    "    rangos = df.apply(lambda col: rango(col), axis=0)\n",
    "    info_df = pd.concat([dtypes, nulls, nuniques, ejemplos, rangos], axis=1)\n",
    "    info_df.columns = ['TipoDato',\"PorcentajeNulos\",\"ValoresUnicos\",\"Ejemplos\", \"Rangos\"]\n",
    "    return info_df\n",
    "\n",
    "tabla = get_dataframe_info(raw_df)\n",
    "#tabla.to_latex()\n",
    "dfi.export(tabla, \"img/tabla1.png\")\n",
    "tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza Texto y Columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan los registros con currency = ARS y se dropea esa columna por carecer de valor predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df[raw_df['currency']== \"USD\"]\n",
    "raw_df.drop(columns='currency', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset posee 8 registros de tipo de propiedad \"Casa de campo\". Se considera que con un número tan bajo de registros no será posible realizar predicciones de calidad para ese tipo de propiedad, por lo que se eliminan los registros del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df[raw_df['property_type']!= \"Casa de campo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de campos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte se realiza una limpieza básica con `regex` de algunas columnas a los fines de normalizar un poco el texto: lowering, punctuation, spaces, digits. La función armada permite customizar la limpieza, por ende es posible no aplicar la misma limpieza para todos los casos. La función genera columnas nuevas con el nombre`f\"{col}_cleaned\"`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las columnas textuales `title` y `description` no fueron utilizadas en la predicción ni analizadas mediante técnicas de embeddings o BOW, no se trataron los NaN en esas columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning import CleaningData\n",
    "#instanciamos Cleaning Data con df\n",
    "\n",
    "cleaned = CleaningData(data=raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning columns with no valuable information...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179798, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quitamos columnas \n",
    "cols_to_drop = [#'Unnamed: 0.1', 'Unnamed: 0', #columnas que vinieron mal en la bajada\n",
    "                'operation_type', #todos son 'venta'\n",
    "                'l1', #todas las filas iguales \n",
    "                'l2', #todas las filas iguales \n",
    "                'ad_type', #todas las filas iguales \n",
    "                'l5', #columna con todas las filas nulas\n",
    "                'l6', #columna con todas las filas nulas\n",
    "                'created_on', #la columna created_on es igual a la columna start_date\n",
    "                'price_period' #la columna contiene muchos NaN y un único valor\n",
    "               ]\n",
    "data = cleaned.drop_columns(columns=cols_to_drop)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza title\n",
    "params = {'lowering':True,'punctuation':True,'accents': True,'strip_spaces':True,'digits':False,'within_spaces':True}\n",
    "cleaned.text_col_cleaning(text_column=\"title\", params=params)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza description\n",
    "params = {'lowering':True,'punctuation':True,'accents': True,'strip_spaces':True,'digits':False,'within_spaces':True}\n",
    "cleaned.text_col_cleaning(text_column=\"description\", params=params)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza texto de l3\n",
    "params = {'lowering':False,'punctuation':True,'accents': True,'strip_spaces':True,'digits':False,'within_spaces':True}\n",
    "cleaned.text_col_cleaning(text_column=\"l3\", params=params)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejoras en la delimitación e imputación de barrios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[['lat','lon','l3_cleaned']].isna().sum()/len(data)).apply(lambda x: \"{:.2%}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se detectó una mayor presencia de valores nulos en los datos de georreferenciación que en el dato del barrio. Por ende se realizó un trabajo de imputación de nulos partiendo de considerar a la columna `l3_cleaned` con una mayor validez que la columnas `lat` y `lon`. Por ende, fue tomada como \"eje\" para realizar imputación de nulos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se analizaron los barrios cuya denomiación no es la denominación oficial: Ejemplo Centro / Microcentro, Las Cañitas, Pompeya, Abasto, Once, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.l3_cleaned.dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se analizaron registros para los que la variable `lat` presentó valores fuera del polígono de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se analizaron registros para los que la variable `lon` presentó valores fuera del polígono de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento realizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se establecieron los siguientes pasos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A los registros cuya localización no correspondía a CABA se les imputó NaN, para ello se utilizó geoJson del polígono de CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path = \"./metadata/provincia.json\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as js: \n",
    "    js = json.load(js)\n",
    "\n",
    "\n",
    "poligono_caba = [tuple(x) for x in js['features'][0]['geometry']['coordinates'][0][0]]\n",
    "\n",
    "from geoBarrios import point_in_polygon\n",
    "\n",
    "def is_caba(coord): \n",
    "    return(point_in_polygon(coord, poligono_caba))\n",
    "\n",
    "data['is_caba'] = [is_caba((lon, lat)) for lon, lat in zip(data.lon, data.lat)]\n",
    "\n",
    "print(f\"Fueron {(data.is_caba==False).sum()} los casos en que la localización era externa a CABA\")\n",
    "\n",
    "data.loc[~data.is_caba, ['lon','lat']] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(8,4))\n",
    "\n",
    "lon , lat = raw_df.lon , raw_df.lat #guardo la localización como vino del dataset\n",
    "axs[0].scatter(lon,lat)\n",
    "axs[0].set_title(\"Localización con Errores\")\n",
    "\n",
    "axs[1].scatter(data.lon,data.lat)\n",
    "plt.title(\"Localización sin Errores\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 1: Normalización datos de barrios porteños: dado que eran pocos casos en los que el inmueble pertenecía a un barrio no oficial de CABA según la columna `l3_cleaned` se realizó una imputación manual. Ej: Las Canitas ---> Palermo. Pompeya --> Nueva Pompeya. Abasto --> Almagro. En un trabajo posterior debería ser revisado y refinado ya que hay casos como Once, Parque Centenario, que son zonas pertenecientes a una mezcla de barrios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = {\n",
    "    'Pompeya': 'Nueva Pompeya',\n",
    "    'Las Canitas': 'Palermo',\n",
    "    'Parque Centenario': 'Caballito', #Puede haber propiedades que en realidad pertenezcan a Almagro o Caballito\n",
    "    'Centro Microcentro':'San Nicolas',\n",
    "    'Tribunales':'San Nicolas',\n",
    "    'Once':'Balvanera',  #puede haber propiedades que en realidd pertenezcan a Almagro.\n",
    "    'Abasto':\"Balvanera\",  #puede haber propiedades que en realidad pertenezcan a Almagro. \n",
    "    \"Catalinas\":\"Retiro\", # la mayor parte de los casos caen ahí (algunos en Boca) \n",
    "    'Congreso':\"Balvanera\", #La mayor parte de los casos caen ahí (algunos en Belgrano)\n",
    "    \"Villa Riachuelo\":\"Villa Lugano\", #Al ser pocas propiedades se imputó el barrio más próximo.\n",
    "}\n",
    "\n",
    "data['l3_norm'] = data.l3_cleaned.apply(lambda x: normalizador[x] if x in normalizador else x)\n",
    "data['l4_nuevo'] = np.where(data.l4.isna()==False, data.l4, \n",
    "                            np.where(data.l3_cleaned != data.l3_norm, data.l3_cleaned, data.l3_norm)\n",
    "                           )\n",
    "\n",
    "\n",
    "gr1 = data.groupby(\"l3_norm\")['id'].count().sort_values(ascending=False)\n",
    "\n",
    "gr2 = data.groupby(\"l4_nuevo\")['id'].count().sort_values(ascending=False)\n",
    "\n",
    "fig, axs = plt.subplots(figsize = (12,10) , ncols=2)\n",
    "\n",
    "\n",
    "barrios = gr1.index\n",
    "cantidad1 = gr1.values\n",
    "\n",
    "sub_barrios = gr2.index\n",
    "cantidad2 = gr2.values\n",
    "\n",
    "axs[0].barh(barrios, cantidad1, align='center')\n",
    "axs[0].invert_yaxis()  # labels read top-to-bottom\n",
    "axs[0].set_xlabel('Cantidad')\n",
    "axs[0].set_title('Barrios')\n",
    "\n",
    "axs[1].barh(sub_barrios, cantidad2, align='center')\n",
    "axs[1].invert_yaxis()  # labels read top-to-bottom\n",
    "axs[1].set_xlabel('Cantidad')\n",
    "axs[1].set_title('Sub-barrios')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 2: Si para un registro el par de columnas `lat`, `lon` presentaron valores NaN, se imputó el valor para cada columna con el promedio de las coordenadas del barrio. Si para dicho registro el dato del barrio fue nulo entonces se quitó toda la fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_location = (data['lat'].isna()) & data['lon'].isna() & (data['l3_norm'].isna())\n",
    "print(f\"Fueron {no_location.sum()} los casos en que no habia locación\")\n",
    "data = data[~no_location].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aquellas propiedades que sí tenían barrio, pero no las coordenadas geográficas, se imputó para cada columna con el promedio barrial de las coordenadas geográficas presentes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_barrios = data.groupby('l4_nuevo')[['lat', 'lon']].mean().reset_index()\n",
    "lat_lon_barrios.columns = ['l4_nuevo','lat_barrio', 'lon_barrio']\n",
    "\n",
    "data = pd.merge(data, lat_lon_barrios, how=\"left\", left_on='l4_nuevo', right_on = 'l4_nuevo')\n",
    "\n",
    "data['lat'] = np.where(data['lat'].isna(), data['lat_barrio'], data['lat'])\n",
    "data['lon'] = np.where(data['lon'].isna(), data['lon_barrio'], data['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Luego de este procesamiento si el barrio del registro presentaba un valor NaN se imputó el barrio correspondiente a la coordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoBarrios import geoBarrios, coord_to_nbhd\n",
    "barrios_dict = geoBarrios()\n",
    "print(f\"Un total de {data.l4_nuevo.isna().sum()} casos poseían barrio nulo y se les imputo el barrio correspondiente a la coordenada\") \n",
    "data.loc[data.l4_nuevo.isna(), \"l4_nuevo\"] = data[data.l4_nuevo.isna()].apply(lambda row: coord_to_nbhd(coord=(row.lon,row.lat),polygons_dict=barrios_dict), axis=1).values\n",
    "data.loc[data.l3_norm.isna(), \"l3_norm\"] = data[data.l3_norm.isna()].apply(lambda row: coord_to_nbhd(coord=(row.lon,row.lat),polygons_dict=barrios_dict), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = [\"l3\",\"l3_cleaned\",\"l4\",\"is_caba\",\"lat_barrio\",\"lon_barrio\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pendiente para un próximo abordaje**\n",
    "\n",
    "* Para los casos en que la localización era externa a CABA y el barrio no nulo, se imputó un punto centroide del barrio. Eso pudo conducir a errores dado que implícitamente se \"confía\" en que el dato del barrio fue correcto. Una alternativa sería probar adicionalmente si de la columna `description_cleaned` fuera posible confirmar que no se tratase de casos que efectivamente pertenecieran a localizaciones externas a CABA. \n",
    "* Si el barrio y la localización no son nulos pero sí incongruentes (localización pertence a otro barrio) se procedío a imputar el punto centroide del barrio. . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo sobre las variables: superficie total, superficie cubierta, ambientes, dormitorios y precio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"surface_total\",\"surface_covered\",\"rooms\",\"bedrooms\", \"price\"]\n",
    "(data[cols].isna().sum()/len(data)).apply(lambda x: \"{:.2%}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exploraron los valores no nulos las columnas `rooms` y `bedrooms`, según el tipo de propiedad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*(data[['rooms','bedrooms']].isnull()==False).groupby(data['property_type']).sum().div(data.groupby(\"property_type\")['rooms','bedrooms'].apply(lambda gr: len(gr)), axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las columnas `rooms` y `bedrooms` poseen muchos nulos siempre que los avisos se traten de cocheras, depósitos, locales comerciales, lotes, oficinas, otros. Para las propiedades utilizadas como vivienda en cambio la presencia de nulos es mucho menor. Por ende en los casos en que las propiedades no sean para vivienda los nulos se completan con valor 0. \n",
    "* Luego de esto dada la alta correlación entre `surface_total` y `surface_covered` y entre `rooms` y `bedrooms`, para los casos en que el par tuviera datos nulos se procedió a eliminar la fila ante la dificultad para imputar nulos en esos casos. \n",
    "* Para la variable `price` se eliminaron las filas que tenían nulos ya que por ser la variable sobre la cual se constuirá la variable respuesta se decidió no realizar imputación de valores faltantes sobre la misma. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `surface_total < surface_covered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.surface_total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.surface_total < data.surface_covered).sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outliers en `surface_covered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.surface_covered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `rooms < bedrooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.rooms < data.bedrooms).sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outliers en `rooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rooms.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outliers en `bedrooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.bedrooms.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento realizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Imputar 0 en las columnas `['rooms','bedrooms']` cuando se trate de cocheras, depósitos, locales comerciales, lotes, oficinas, otros. \n",
    "1) Borrar filas donde los pares de columnas `['rooms','bedrooms']` o `['surface_total','surface_covered']` contengan nulos. \n",
    "2) Intercambiar los valores de las columnas cuando `rooms < bedrooms` o `surface_total < surface_covered`. \n",
    "3) Eliminar filas donde `price` sea nulo. \n",
    "4) Si para una fila uno de los valores de `['surface_total', 'surface_covered']` contiene valor outlier y el otro no es outlier, se le imputó un `NaN` al dato outlier y se dejó dicho valor para ser imputado luego por método MICE. En caso que los dos valores fueran outliers o uno outlier y el otro `NaN` se borró la fila. \n",
    "5) Si para una fila uno de los valores de `['rooms', bedrooms']` contiene valor outlier y el otro no es outlier, se le imputó un `NaN` al dato outlier y se dejó dicho valor para ser imputado luego por método MICE. En caso que los dos valores fueran outliers o uno outlier y el otro `NaN` se borró la fila. \n",
    "6) Se borraron los valores outliers de `price`\n",
    "7) Luego de estos pasos se procedió a imputar los valores nulos con el método multivariado MICE en las columnas `['rooms', bedrooms','surface_total','surface_covered']` utilizando también la variable `price` como predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazar rooms y bedrooms 0 para property_type 'Local comercial', 'Depósito', 'Cochera', 'Lote', 'Oficina', 'Otro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.property_type.isin([\"Cochera\",\"Depósito\",\"Local comercial\",\"Lote\",\"Oficina\",\"Otro\"]),[\"rooms\",\"bedrooms\"]] = data.loc[data.property_type.isin([\"Cochera\",\"Depósito\",\"Local comercial\",\"Lote\",\"Oficina\",\"Otro\"]),[\"rooms\",\"bedrooms\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_rb = data[data[['rooms', 'bedrooms']].isna().any(axis=1)][['rooms', 'bedrooms', 'l3_norm']].groupby('l3_norm').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#punto 1\n",
    "data.dropna(subset = ['rooms', 'bedrooms'], how = 'all', inplace = True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = ['surface_total', 'surface_covered'], how = 'all', inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset =['price'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['rooms','bedrooms']].isnull().groupby(data['property_type']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* outlieres en `surface_total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#punto 2\n",
    "idx = data[data.surface_total<data.surface_covered].index\n",
    "data.loc[idx,['surface_total','surface_covered']] = data.loc[idx,['surface_covered','surface_total']].values\n",
    "\n",
    "idx = data[data.rooms<data.bedrooms].index\n",
    "data.loc[idx,['rooms','bedrooms']] = data.loc[idx,['bedrooms','rooms']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Si para una fila uno de los valores de ['surface_total', 'surface_covered'] contiene valor outlier y el otro no es outlier, se le imputó un NaN al dato outlier y se dejó dicho valor para ser imputado luego por método MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos quantiles .01 y .99 para surface_total\n",
    "data_st = data[['l3_norm', 'property_type', 'surface_total', 'rooms']]\n",
    "data_st_q99 = data_st.groupby(['l3_norm', 'property_type', 'rooms']).quantile(.99)\n",
    "data_st_q99.rename(columns = {'surface_total':'p99_surface_total'}, inplace = True)\n",
    "\n",
    "data_sc = data[['l3_norm', 'property_type', 'surface_covered', 'rooms']]\n",
    "data_sc_q99 = data_sc.groupby(['l3_norm', 'property_type', 'rooms']).quantile(.99)\n",
    "data_sc_q99.rename(columns = {'surface_covered':'p99_surface_covered'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(data_st_q99, how = \"left\", on = (['l3_norm', 'property_type', 'rooms']))\n",
    "data = data.merge(data_sc_q99, how = \"left\", on = (['l3_norm', 'property_type', 'rooms']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generamos quantiles .01 y .99 para surface_covered\n",
    "data_st_q01 = data_st.groupby(['l3_norm', 'property_type', 'rooms']).quantile(.01)\n",
    "data_st_q01.rename(columns = {'surface_total':'p01_surface_total'}, inplace = True)\n",
    "\n",
    "data_sc_q01 = data_sc.groupby(['l3_norm', 'property_type', 'rooms']).quantile(.01)\n",
    "data_sc_q01.rename(columns = {'surface_covered':'p01_surface_covered'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(data_st_q01, how = \"left\", on = (['l3_norm', 'property_type', 'rooms']))\n",
    "data = data.merge(data_sc_q01, how = \"left\", on = (['l3_norm', 'property_type', 'rooms']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros con un outlier en surface_total\n",
    "data[(data['surface_total'] > data['p99_surface_total']) | (data['surface_total'] < data['p01_surface_total'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros con un outlier en surface_covered\n",
    "data[(data['surface_covered'] > data['p99_surface_covered']) | (data['surface_covered'] < data['p01_surface_covered'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino registros con 2 precios outliers\n",
    "data = data[(data['surface_total'] < data['p99_surface_total']) & (data['surface_total'] > data['p01_surface_total']) & (data['surface_covered'] < data['p99_surface_covered']) & (data['surface_covered'] > data['p01_surface_covered'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros con un outlier en surface_covered\n",
    "data[(data['surface_covered'] > data['p99_surface_covered']) | (data['surface_covered'] < data['p01_surface_covered'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros con un outlier en surface_total\n",
    "data[(data['surface_total'] > data['p99_surface_total']) | (data['surface_total'] < data['p01_surface_total'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso a NA el registro outlier de surface_total o surface_covered\n",
    "data['surface_total'] = np.where((data['surface_total'] > data['p99_surface_total']) | (data['surface_total'] < data['p01_surface_total']), np.nan, data['surface_total'])\n",
    "data['surface_covered'] = np.where((data['surface_covered'] > data['p99_surface_covered']) | (data['surface_covered'] < data['p01_surface_covered']), np.nan, data['surface_covered'])\n",
    "#Dropeo columnas accesorias\n",
    "data = data.drop(columns= ['p99_surface_total', 'p01_surface_total', 'p99_surface_covered', 'p01_surface_covered'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso que los dos valores de 'surface_covered' y 'surface_total' fueran outliers o uno outlier y el otro NaN se borró la fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['surface_covered', 'surface_total'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5) Si para una fila uno de los valores de ['rooms', bedrooms'] contiene valor outlier y el otro no es outlier, se le imputó un NaN al dato outlier y se dejó dicho valor para ser imputado luego por método MICE. En caso que los dos valores fueran outliers o uno outlier y el otro NaN se borró la fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['property_type','rooms']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['property_type','bedrooms']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imputan con 1 los registros con valor negativo de bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bedrooms'] = np.where(data['bedrooms']<0, 1, data['bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['property_type','bedrooms']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6) Se borraron los valores outliers de price agrupados por barrio, tipo de propiedad y cuartos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pr = data[['l3_norm', 'property_type', 'price', 'rooms']]\n",
    "data_pr_q99 = data_pr.groupby(['l3_norm', 'property_type', 'rooms']).quantile(.99)\n",
    "data_pr_q99.rename(columns = {'price':'p99_price'}, inplace = True)\n",
    "data_pr_q01 = data_pr.groupby(['l3_norm', 'property_type', 'rooms']).quantile(.01)\n",
    "data_pr_q01.rename(columns = {'price':'p01_price'}, inplace = True)\n",
    "data = data.merge(data_pr_q99, how = \"left\", on = (['l3_norm', 'property_type', 'rooms']))\n",
    "data = data.merge(data_pr_q01, how = \"left\", on = (['l3_norm', 'property_type', 'rooms']))\n",
    "#Eliminamos precios outliers\n",
    "data = data[(data['price']< data['p99_price']) & (data['price'] > data['p01_price'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Reimputación de bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data \n",
    "index_orig= df.index\n",
    "index_orig2= df.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veo cuales son los valores medios de 'bathroom\" para cada cantidad de ambientes por cada tipo de propiedad --> y lo guardo en un nuevo df llamado 'bath_med'\n",
    "cols = ['rooms','bathrooms', 'property_type']\n",
    "medxprop = df[cols].groupby(['rooms','property_type']).median()#.rename({'bathrooms':'bathrooms_med'},axis=1).round(0)\n",
    "medxprop = medxprop.rename({'bathrooms':'bathrooms_med'},axis=1).round(0)\n",
    "bath_med = medxprop.reset_index()\n",
    "bath_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrego una nueva columna al df con esa mediana calculada para luego imputar los nulls en bathrooms con ese dato\n",
    "df = df.merge(bath_med, 'left', on = ['rooms','property_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputamos: le asignamos la mediana x tipo y cant. rooms\n",
    "mask = df['bathrooms'].isna()\n",
    "df.loc[mask, 'bathrooms'] = df.loc[mask,'bathrooms_med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que no hay nulls\n",
    "df['bathrooms'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le volvemos a poner el indice y lo renombramos al nombre previo:\n",
    "df = df.set_index(index_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCION REQUERIDA: volver al nombre original --> df_Actual_Name\n",
    "data = df #--> CAMBIAR df_Actual_Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de Pre-procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas iniciales: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas a exportar por este script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputación de datos faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset presentaba una gran cantidad de datos faltantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más importante aún, todos los registros del dataset poseían al menos un dato faltante, por lo que no existían registros aptos para utilizar en un algoritmo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_df.isnull().any(axis=1)) #Nro de filas con al menos un dato faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_df.isnull().any(axis=1)) - len(~raw_df.isnull().any(axis=1)) #Nro de filas del dataset - Nro de filas con al menos un dato faltante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de normalización, imputación y selección inicial de features permitió imputar y recuperar el siguiente número de filas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros iniciales y finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filas iniciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filas a exportar por este script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este csv es recuperado por el script de Feature Engineering para generar variables adicionales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('resultados/cabaventa_preproc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "end_time = time.time()\n",
    "elapsed = str(datetime.timedelta(seconds=end_time - start_time))\n",
    "print(f\"Time execution is {elapsed}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "112989f40982219f9c2133127490be09f86560db102a13a350eb86b01002b443"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
